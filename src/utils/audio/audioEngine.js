import * as Tone from 'tone'
import { AUDIO_CONFIG } from '../../config/constants'

/**
 * ä¸“ä¸šéŸ³é¢‘å¼•æ“
 * è´Ÿè´£æ‰€æœ‰éŸ³é¢‘å¤„ç†ã€æ•ˆæœé“¾ç®¡ç†å’Œå®æ—¶åˆ†æ
 */
class AudioEngine {
  constructor() {
    this.audioContext = null
    this.masterOutput = null
    this.inputStream = null
    this.analyser = null
    this.effectsChain = {}
    this.isInitialized = false
    this.isRecording = false
    
    // éŸ³é¢‘èŠ‚ç‚¹æ± 
    this.nodes = {
      input: null,
      recorder: null,
      pitchDetector: null,
      harmonyGenerator: null,
      effects: {},
      output: null
    }
    
    // çŠ¶æ€
    this.state = {
      volume: 0.7,
      isMuted: false,
      currentEffect: null,
      magicMode: false
    }
    
    // éŸ³é¢‘æ•°æ®ç¼“å­˜
    this.audioData = {
      waveform: new Float32Array(AUDIO_CONFIG.FFT_SIZE / 2),
      spectrum: new Uint8Array(AUDIO_CONFIG.FFT_SIZE / 2),
      pitch: 0,
      confidence: 0,
      harmonyVoices: []
    }
  }
  
  /**
   * åˆå§‹åŒ–éŸ³é¢‘å¼•æ“
   */
  async initialize() {
    try {
      // ç­‰å¾…ç”¨æˆ·äº¤äº’ï¼ˆæµè§ˆå™¨å®‰å…¨ç­–ç•¥ï¼‰
      await Tone.start()
      
      // åˆ›å»ºéŸ³é¢‘ä¸Šä¸‹æ–‡
      this.audioContext = Tone.getContext().rawContext
      
      // åˆ›å»ºä¸»è¾“å‡ºé“¾
      this.masterOutput = new Tone.Volume(this.state.volume).toDestination()
      
      // åˆ›å»ºåˆ†æå™¨
      this.analyser = new Tone.Analyser('waveform', AUDIO_CONFIG.FFT_SIZE)
      this.analyser.smoothing = AUDIO_CONFIG.SMOOTHING_TIME
      
      // åˆå§‹åŒ–æ•ˆæœé“¾
      await this.initializeEffects()
      
      // åˆ›å»ºå½•éŸ³å™¨
      this.recorder = new Tone.Recorder()
      
      this.isInitialized = true
      console.log('âœ… éŸ³é¢‘å¼•æ“åˆå§‹åŒ–å®Œæˆ')
      
      return true
    } catch (error) {
      console.error('âŒ éŸ³é¢‘å¼•æ“åˆå§‹åŒ–å¤±è´¥:', error)
      return false
    }
  }
  
  /**
   * åˆå§‹åŒ–æ•ˆæœå¤„ç†å™¨
   */
  async initializeEffects() {
    // ç¾åŒ–æ•ˆæœï¼ˆç”¨æˆ·å¯è¾¾ç›®æ ‡ï¼‰
    this.effectsChain.beautify = new Tone.Chain(
      new Tone.AutoPanner().start(),
      new Tone.AutoFilter().start(),
      new Tone.Chorus(4, 2.5, 0.5).start(),
      new Tone.Reverb({
        decay: 2.5,
        preDelay: 0.01,
        wet: AUDIO_CONFIG.BEAUTIFY.REVERB_WET
      }).generate(),
      new Tone.FeedbackDelay({
        delayTime: '8n',
        feedback: AUDIO_CONFIG.BEAUTIFY.DELAY_FEEDBACK,
        wet: 0.3
      }),
      this.masterOutput
    )
    
    // é­”æ³•æ•ˆæœï¼ˆç†æƒ³å¤¸å¼ æ•ˆæœï¼‰
    this.effectsChain.magic = new Tone.Chain(
      new Tone.AutoPanner(0.5).start(),
      new Tone.AutoFilter({
        frequency: '4n',
        baseFrequency: 200,
        octaves: 4
      }).start(),
      new Tone.Chorus(6, 3.5, 0.8).start(),
      new Tone.Reverb({
        decay: 4,
        preDelay: 0.02,
        wet: AUDIO_CONFIG.MAGIC.REVERB_WET
      }).generate(),
      new Tone.FeedbackDelay({
        delayTime: '4n',
        feedback: AUDIO_CONFIG.MAGIC.DELAY_FEEDBACK,
        wet: 0.5
      }),
      new Tone.Compressor({
        ratio: AUDIO_CONFIG.MAGIC.COMPRESSION_RATIO,
        threshold: -24,
        attack: 0.003,
        release: 0.25
      }),
      this.masterOutput
    )
    
    // å¹²å£°é€šé“ï¼ˆæ— æ•ˆæœï¼‰
    this.effectsChain.dry = this.masterOutput
    
    // è®¾ç½®å½“å‰æ•ˆæœ
    this.state.currentEffect = 'beautify'
  }
  
  /**
   * è·å–ç”¨æˆ·éº¦å…‹é£è¾“å…¥
   */
  async getUserMicrophone() {
    try {
      if (!this.isInitialized) {
        await this.initialize()
      }
      
      // è¯·æ±‚éº¦å…‹é£æƒé™
      this.inputStream = await navigator.mediaDevices.getUserMedia({
        audio: {
          echoCancellation: false,
          noiseSuppression: false,
          autoGainControl: false,
          channelCount: 1,
          sampleRate: AUDIO_CONFIG.SAMPLE_RATE
        }
      })
      
      // åˆ›å»ºè¾“å…¥èŠ‚ç‚¹
      this.nodes.input = new Tone.UserMedia()
      await this.nodes.input.open(this.inputStream)
      
      // è¿æ¥åˆ°æ•ˆæœé“¾å’Œåˆ†æå™¨
      this.nodes.input.connect(this.effectsChain[this.state.currentEffect])
      this.nodes.input.connect(this.analyser)
      
      console.log('ğŸ¤ éº¦å…‹é£è¾“å…¥å·²è¿æ¥')
      return true
      
    } catch (error) {
      console.error('âŒ æ— æ³•è·å–éº¦å…‹é£:', error)
      throw error
    }
  }
  
  /**
   * å¼€å§‹å¤„ç†éŸ³é¢‘è¾“å…¥
   */
  async startProcessing() {
    if (!this.nodes.input) {
      await this.getUserMicrophone()
    }
    
    // å¼€å§‹éŸ³é¢‘åˆ†æ
    this.startAnalysis()
    
    console.log('â–¶ï¸ éŸ³é¢‘å¤„ç†å·²å¼€å§‹')
  }
  
  /**
   * å¼€å§‹éŸ³é¢‘åˆ†æ
   */
  startAnalysis() {
    if (!this.analyser) return
    
    const analyze = () => {
      if (!this.isInitialized) return
      
      // è·å–æ³¢å½¢æ•°æ®
      this.audioData.waveform = this.analyser.getValue()
      
      // è·å–é¢‘è°±æ•°æ®
      this.audioData.spectrum = new Uint8Array(
        this.analyser.getValue('fft').map(v => (v + 1) * 128)
      )
      
      // è¯·æ±‚ä¸‹ä¸€å¸§
      requestAnimationFrame(analyze)
    }
    
    analyze()
  }
  
  /**
   * åˆ‡æ¢æ•ˆæœæ¨¡å¼
   * @param {string} effect - æ•ˆæœæ¨¡å¼: 'dry' | 'beautify' | 'magic'
   */
  setEffectMode(effect) {
    if (!this.effectsChain[effect]) {
      console.warn(`æ•ˆæœæ¨¡å¼ ${effect} ä¸å­˜åœ¨`)
      return
    }
    
    // æ–­å¼€å½“å‰è¿æ¥
    if (this.nodes.input && this.state.currentEffect) {
      this.nodes.input.disconnect(this.effectsChain[this.state.currentEffect])
      this.nodes.input.disconnect(this.analyser)
    }
    
    // è¿æ¥åˆ°æ–°æ•ˆæœ
    this.nodes.input.connect(this.effectsChain[effect])
    this.nodes.input.connect(this.analyser)
    
    this.state.currentEffect = effect
    this.state.magicMode = effect === 'magic'
    
    console.log(`ğŸ›ï¸ åˆ‡æ¢åˆ° ${effect} æ•ˆæœæ¨¡å¼`)
    
    return effect
  }
  
  /**
   * åº”ç”¨å’Œå£°ç”Ÿæˆ
   * @param {number} interval - å’Œå£°éŸ³ç¨‹ï¼ˆåŠéŸ³æ•°ï¼‰
   * @param {number} intensity - å’Œå£°å¼ºåº¦ 0-1
   */
  applyHarmony(interval, intensity = 1.0) {
    // è¿™é‡Œå°†å®ç°å®æ—¶å’Œå£°ç”Ÿæˆ
    // ä½¿ç”¨ Tone.PitchShift æˆ–è‡ªå®šä¹‰ç®—æ³•
    console.log(`ğŸµ åº”ç”¨å’Œå£°: ${interval} åŠéŸ³, å¼ºåº¦: ${intensity}`)
    
    // TODO: å®ç°å®æ—¶å’Œå£°ç”Ÿæˆ
    return interval
  }
  
  /**
   * å¼€å§‹å½•éŸ³
   */
  async startRecording() {
    if (!this.isInitialized) return
    
    this.isRecording = true
    this.recorder.start()
    
    console.log('ğŸ”´ å¼€å§‹å½•éŸ³')
  }
  
  /**
   * åœæ­¢å½•éŸ³å¹¶è·å–å½•éŸ³æ•°æ®
   */
  async stopRecording() {
    if (!this.isRecording) return
    
    this.isRecording = false
    const recording = await this.recorder.stop()
    
    console.log('â¹ï¸ å½•éŸ³åœæ­¢')
    return recording
  }
  
  /**
   * æ’­æ”¾éŸ³é¢‘ç¼“å†²
   * @param {AudioBuffer} buffer - éŸ³é¢‘ç¼“å†²
   * @param {Object} options - æ’­æ”¾é€‰é¡¹
   */
  playBuffer(buffer, options = {}) {
    const player = new Tone.Player(buffer)
    
    if (options.loop) {
      player.loop = true
      player.loopStart = options.loopStart || 0
      player.loopEnd = options.loopEnd || buffer.duration
    }
    
    player.connect(this.effectsChain[options.effect || this.state.currentEffect])
    player.start(options.startTime)
    
    return player
  }
  
  /**
   * è·å–å½“å‰éŸ³é¢‘æ•°æ®
   */
  getAudioData() {
    return {
      ...this.audioData,
      effectMode: this.state.currentEffect,
      isMagicMode: this.state.magicMode,
      isRecording: this.isRecording
    }
  }
  
  /**
   * è®¾ç½®éŸ³é‡
   * @param {number} volume - éŸ³é‡ 0-1
   */
  setVolume(volume) {
    const clampedVolume = Math.max(0, Math.min(1, volume))
    this.state.volume = clampedVolume
    
    if (this.masterOutput) {
      this.masterOutput.volume.value = Tone.gainToDb(clampedVolume)
    }
  }
  
  /**
   * é™éŸ³/å–æ¶ˆé™éŸ³
   */
  toggleMute() {
    this.state.isMuted = !this.state.isMuted
    
    if (this.masterOutput) {
      this.masterOutput.mute = this.state.isMuted
    }
    
    return this.state.isMuted
  }
  
  /**
   * æ¸…ç†èµ„æº
   */
  async cleanup() {
    if (this.inputStream) {
      this.inputStream.getTracks().forEach(track => track.stop())
    }
    
    if (this.nodes.input) {
      this.nodes.input.close()
    }
    
    if (Tone.context.state !== 'closed') {
      await Tone.context.close()
    }
    
    this.isInitialized = false
    console.log('ğŸ§¹ éŸ³é¢‘å¼•æ“èµ„æºå·²æ¸…ç†')
  }
}

// å•ä¾‹æ¨¡å¼å¯¼å‡º
const audioEngine = new AudioEngine()
export default audioEngine